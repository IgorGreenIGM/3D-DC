# 3D Data Compression Algorithm

This project is a C++ implementation of a 3D data compression algorithm based on the principle of **Shannon Entropy Reduction**. The goal is to reduce file size by applying predictive filtering methods to the data, which minimizes its entropy and makes it more compressible.

The repository also includes Python scripts for testing and visualizing the algorithm's performance.

## How It Works

The compression algorithm processes data in three main stages:

1.  **`DCBuffer`**: Reads data from a file into a buffer, preparing it for processing.
2.  **`DCQueue`**: The core of the algorithm. It applies 2D and 3D filters to reduce the data's entropy. By making the data less random, it becomes more suitable for compression.
3.  **`DCMap`**: Provides a coordinate system to navigate and manipulate the 3D data, enabling advanced operations like analyzing neighboring data points.

## Getting Started

### Prerequisites

*   A C++ compiler (like GCC)
*   Python 3.x
*   `matplotlib` and `rar` (for the Python scripts)

### Compilation

To compile the C++ program, run the following command in the root directory:

```bash
make
```

This will create an executable file named `output.exe` in the root directory.

### Usage

The `scrapper.py` script can be used to run the compression algorithm with different settings and generate output files for analysis.

```bash
python scrapper.py
```

The script will run the C++ executable on an image file (`img.png`) with various matrix sizes and apply 2D, 3D, and combined 2D/3D filters. The results are saved in `matrix_2D.txt`, `matrix_3D.txt`, and `matrix_2D_3D.txt`.

### Visualization

The `plotter.ipynb` Jupyter Notebook reads the output files generated by `scrapper.py` and creates a plot to visualize the compression performance. The plot compares the original file size to the compressed sizes after applying different filtering methods.
